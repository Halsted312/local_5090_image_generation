services:
  db:
    image: postgres:15
    environment:
      POSTGRES_USER: flexyface
      POSTGRES_PASSWORD: flexypass
      POSTGRES_DB: flexyface
    volumes:
      - db_data:/var/lib/postgresql/data
    ports:
      - "7432:5432"

  backend:
    build: ./backend
    env_file:
      - .env
    environment:
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_HUB_TOKEN:-}
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - DATABASE_URL=${DATABASE_URL:-postgresql+psycopg2://flexyface:flexypass@db:5432/flexyface}
      - PRANK_IMAGE_ROOT=/data/prank_images
      - PRANK_LLM_ID=${PRANK_LLM_ID:-meta-llama/Meta-Llama-3-8B-Instruct}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-changeme}
      - GPU_COORD_PATH=/gpu_coord/status.json
      - EXCLUDED_LIVE_MODELS=${EXCLUDED_LIVE_MODELS:-hidream_dev}
    volumes:
      - hf_cache:/root/.cache/huggingface
      - ./prank_images:/data/prank_images
      - gpu-coord:/gpu_coord
    ports:
      - "7999:7999"
    depends_on:
      - db
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  frontend:
    build: ./frontend_archive_ignore
    ports:
      - "7080:80"
    depends_on:
      - backend

  benchmark:
    build:
      context: .
      dockerfile: research/Dockerfile.benchmark
    env_file:
      - .env
    environment:
      - GPU_COORD_PATH=/gpu_coord/status.json
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_HUB_TOKEN}
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - HF_HOME=/workspace/hf_cache
    volumes:
      - gpu-coord:/gpu_coord
      - hf_cache:/workspace/hf_cache
      - ./research:/workspace/research:ro
      - ./research/benchmark_results:/workspace/benchmark_results
    command: ["python", "research/benchmarks/efficient_benchmark_runner.py"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  hf_cache:
  db_data:
  gpu-coord:
